{
 "metadata": {
  "name": "PDFLiberation"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "\n",
      "from PdfLiberationUtils import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Collect info about the pdf_files to be processed.\n",
      "# Starting point is the url that lists the pdf files.\n",
      "\n",
      "# The main loop will crate new directories\n",
      "# ./download -- to download files from the url\n",
      "# ./ocr      -- for files converted from non-searchable to searchable format (ABBYY)\n",
      "# ./csv      -- for files converted from PDF to CSV format (Tabula), one CSV file per PDF page\n",
      "# ./final    -- for final CSV, where tables spanning mult pages are merged into single CSV\n",
      "env = { \n",
      "    \"url\"            : \"http://www.cityofjerseycity.com\",\n",
      "    \"budget_url\"     : \"http://www.cityofjerseycity.com/pub-info.aspx?id=2430\",\n",
      "    \"dir_download\"   : \"./download/\",\n",
      "    \"dir_ocr\"        : \"./ocr/\",\n",
      "    \"dir_csv\"        : \"./csv/\",\n",
      "    \"dir_final\"      : \"./final/\" }\n",
      "\n",
      "pdf_files = get_pdf_files(env)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "\n",
      "def get_status(pdf_files):\n",
      "    # url\n",
      "    # file name\n",
      "    # Download Status\n",
      "    # num_pages\n",
      "    # is_searchable\n",
      "    # OCR Status - TODO\n",
      "    # Raw CSV Status - TODO\n",
      "    # Merged CSV Status - TODO\n",
      "\n",
      "    data = ([\n",
      "        pdf_file[\"url\"],\n",
      "        pdf_file[\"download_file_name\"].replace(\"./download/\",\"\"),\n",
      "        file_exists(pdf_file[\"download_file_name\"]),\n",
      "        num_pages(pdf_file[\"download_file_name\"]),\n",
      "        is_searchable(pdf_file[\"download_file_name\"]),\n",
      "        file_exists(pdf_file[\"ocr_file_name\"]) #applies only if not searchable\n",
      "        ] for pdf_file in pdf_files)\n",
      "\n",
      "    idx = ([pdf_file[\"download_file_name\"].replace(\"./download/\",\"\") for pdf_file in pdf_files])\n",
      "\n",
      "    cols = (\"url\",\"file_name\",\"download_status\",\"num_pages\",\"is_searchable\",\"ocr_status\")\n",
      "\n",
      "    df = pd.DataFrame(list(data),index=list(idx),columns=cols)\n",
      "\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Main loop\n",
      "# Depending on the number of files, this process may take several hours\n",
      "# ABBYY takes 30 mins for 100 page document\n",
      "\n",
      "for pdf_file in pdf_files:\n",
      "    download_file(pdf_file[\"root_url\"], pdf_file[\"download_file_name\"])\n",
      "    convert_to_searchable_format(pdf_file[\"download_file_name\"], pdf_file[\"ocr_file_name\"])\n",
      "    # TODO: create wrapper\n",
      "    np = num_pages(pdf_file[\"ocr_file_name\"])\n",
      "    for page_number in range(1,np+1):\n",
      "        convert_page_to_csv(pdf_file[\"ocr_file_name\"],page_number)\n",
      "    # TODO: Detect tables running on muliple pages and merge the CSV files, so it's one per table per PDF file\n",
      "    # TODO: Data scraping, converting into structured data\n",
      "    # TODO: Download CSV and .json into https://data.openjerseycity.org/dataset/jersey-city-2013-budget-adopted-spending"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get status of the files, including what was downloaded, searchable, number of pages, etc\n",
      "\n",
      "# TODO:  clean up warning from pyPDF:  \n",
      "# PdfReadWarning: PdfFileReader stream/file object is not in binary mode. It may not be read correctly. [pdf.py:644]\n",
      "# PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will not be corrected. [pdf.py:1130]\n",
      "    \n",
      "df = get_status(pdf_files)\n",
      "print df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test one file\n",
      "\n",
      "#download_file(pdf_files[0][\"root_url\"], pdf_files[0][\"download_file_name\"])\n",
      "#convert_to_searchable_format(pdf_files[0][\"download_file_name\"], pdf_files[0][\"ocr_file_name\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# More ABBYY tests...\n",
      "\n",
      "#convert_to_searchable_format(\"./download/CY2012BudgetAmendmentIntroduced.pdf\", \"./ocr/CY2012BudgetAmendmentIntroduced.pdf\")\n",
      "#convert_to_searchable_format(\"./download/AnnualFinancialStatement2012.pdf\",\"./ocr/largeTest.pdf\") #102 pages\n",
      "#convert_to_searchable_format(\"./download/FY2010AnnualAudit.pdf\",\"./ocr/superLargeTest.pdf\") #236 pages"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}